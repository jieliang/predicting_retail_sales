{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_clean_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean weekly sales data\n",
    "\n",
    "#### challenges in raw data:\n",
    "1. entries are recorded on different days of the week\n",
    "2. some weeks have multiple entires\n",
    "3. between start date and end date, about 20% of all weeks are missing\n",
    "\n",
    "    \n",
    "#### solutions to get clean data:\n",
    "1. normalize dates: since we are dealing with weekly sales, convert all dates to the Monday of that week\n",
    "2. consolidate all records from a week into one dated the Monday of that week by adding their weekly sales together.\n",
    "3. for each missing week, create a record dated the Monday of that week; impute its weekly sales value as follows:\n",
    "    * if it's a non-holiday week, use the weekly sales value from the closeset available non-holiday week\n",
    "    * else (it's a holiday week), use the mean weekly sales from the same holiday if exist,otherwise use the closest avaiable holiday weekly sales. \n",
    "    \n",
    "#### clean data and save in pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import statsmodels.api as sm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_of_year(date):\n",
    "    return date.week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# since we are dealing with weekly data, on which day an entry got recorded is not important\n",
    "# rather, we will normalize them by converting them to the date of Monday of the same week.\n",
    "# later we will aggregate weekly sales by summing all the entry on the same normalized date.\n",
    "def year_week(date):\n",
    "    temp = date.isocalendar()\n",
    "    date_string = str(temp[0])+' '+str(temp[1])+' 1'\n",
    "    return datetime.strptime(date_string, '%G %V %u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data \n",
    "sales=pd.read_csv('data/sales.csv')\n",
    "\n",
    "\n",
    "# normalize dates\n",
    "sales['Date'] = pd.to_datetime(sales['Date'])\n",
    "sales['Date']=sales['Date'].apply(year_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date=min(sales['Date'])\n",
    "end_date=max(sales['Date'])\n",
    "dates = sorted(list(pd.date_range(start_date, end_date, freq='W')))\n",
    "all_dates=[year_week(start_date).date()]+[year_week(d).date() for d in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the weeks when we have data\n",
    "all_dates=list(set(all_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_depts=sorted(sales['Dept'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stores=sorted(sales['Store'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_depts = len(all_depts)\n",
    "n_stores = len(all_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-04-26</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-29</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-15</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-22</td>\n",
       "      <td>19403.54</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-03</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept       Date  Weekly_Sales  IsHoliday\n",
       "0      1     1 2010-04-26      24924.50      False\n",
       "1      1     1 2010-11-29      46039.49       True\n",
       "2      1     1 2010-02-15      41595.55      False\n",
       "3      1     1 2010-02-22      19403.54      False\n",
       "4      1     1 2010-05-03      21827.90      False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "# slice data; look at each (dept, store) combo\n",
    "slice_df = sales.copy(deep=True)\n",
    "groups = dict(list( slice_df.groupby(['Dept','Store'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pandas.tseries.holiday import get_calendar, HolidayCalendarFactory, GoodFriday\n",
    "from datetime import datetime\n",
    "\n",
    "cal = get_calendar('USFederalHolidayCalendar')  # Create calendar instance\n",
    "holidays = list(cal.holidays(start_date, end_date))\n",
    "#convert from actual holiday dates to the dates of first day of holiday weeks\n",
    "holidays = [year_week(day) for day in holidays]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super Bowl: 12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13 Labor Day: 10-Sep-10, 9-Sep-11, 7-Sep-12, 6-Sep-13 Thanksgiving: 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13 Christmas: 31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_holidays = {}\n",
    "\n",
    "super_bowl_dates=[datetime(2010, 2, 12, 0, 0),datetime(2011, 2, 11, 0, 0),datetime(2012, 2, 10, 0, 0),datetime(2013, 2, 8, 0, 0)]\n",
    "labor_day_dates=[datetime(2010, 9, 10, 0, 0),datetime(2011, 9, 9, 0, 0),datetime(2012, 9, 7, 0, 0),datetime(2013, 9, 6, 0, 0)]\n",
    "thanksgiving_dates=[datetime(2010, 11, 26, 0, 0),datetime(2011, 11, 25, 0, 0),datetime(2012, 11, 23, 0, 0),datetime(2013, 11, 29, 0, 0)]\n",
    "xmas_dates=[datetime(2010, 12, 25, 0, 0),datetime(2011, 12, 24, 0, 0),datetime(2012, 12, 22, 0, 0),datetime(2013, 12, 21, 0, 0)]\n",
    "\n",
    "super_bowl_weeks = [year_week(d) for d in super_bowl_dates ]\n",
    "labor_day_weeks= [year_week(d) for d in labor_day_dates ]\n",
    "thanksgiving_weeks = [year_week(d) for d in thanksgiving_dates ]\n",
    "xmas_weeks = [year_week(d) for d in xmas_dates ]\n",
    "\n",
    "for week in super_bowl_weeks:\n",
    "    major_holidays[week] = 'super_bowl'\n",
    "for week in labor_day_weeks:\n",
    "    major_holidays[week] = 'labor_day'\n",
    "for week in thanksgiving_weeks:\n",
    "    major_holidays[week] = 'thanksgiving'\n",
    "for week in xmas_weeks:\n",
    "    major_holidays[week] = 'xmas'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts dates to same form so they can be compared\n",
    "\n",
    "def timestamp_to_date(d):\n",
    "    if len(str(d)) < 13:\n",
    "        return d\n",
    "    date_string = str(d)\n",
    "    date_string = str(d).split(' ')[0]\n",
    "    return datetime.strptime(date_string,'%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* segment data \n",
    "* for each (dept, store) combo, build a data frame then save this data frame in a dict with key (dept, store)\n",
    "* note some (dept, store) do not exist\n",
    "\n",
    "* each data frame holds actual info as well as imputed data for the missing weeks during this 2 year period.\n",
    "\n",
    "* before imputation, weekly sales is set to 0 for missing weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_holiday(date):\n",
    "    return year_week(date) in holidays\n",
    "\n",
    "\n",
    "\n",
    "dfs ={}\n",
    "indices = all_dates\n",
    "invalid_dept_store = []\n",
    "\n",
    "for dept in range(1,n_depts+1):\n",
    "    for store in range(1,n_stores+1):\n",
    "        try:\n",
    "            df = groups[(dept,store)]\n",
    "            df = df[['Date', 'Weekly_Sales', 'IsHoliday']]\n",
    "            \n",
    "            existing_dates = [d.date() for d in df['Date']]\n",
    "            missing_dates = [d for d in all_dates if d not in existing_dates]\n",
    "            num_missing = len(missing_dates)\n",
    "        \n",
    "        \n",
    "            df2=pd.DataFrame()\n",
    "            df2['Date']=missing_dates\n",
    "            df2['Weekly_Sales']=[0]*num_missing\n",
    "        \n",
    "            df2['IsHoliday']=df2['Date'].apply(is_holiday)\n",
    "            df = pd.concat([df,df2], axis=0)\n",
    "            df['Date']=df['Date'].apply(timestamp_to_date)\n",
    "            df=df.set_index('Date')\n",
    "            df=df.sort_index()\n",
    "            # sum multiple entries in the same week\n",
    "            df=df.groupby(level=0).sum()\n",
    "\n",
    "            dfs[(dept,store)] = df\n",
    "        except:\n",
    "            # this key combo does not exist in data\n",
    "            invalid_dept_store.append((dept,store))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "major_holiday_means = {}\n",
    "\n",
    "for dept,store in dfs.keys():\n",
    "    df = dfs[(dept,store)]\n",
    "    df_indices = df.index\n",
    "    holiday_indices = major_holidays.keys()\n",
    "    both = set(df_indices).intersection(set(holiday_indices))\n",
    "    \n",
    "    \n",
    "    super_bowl_mean = np.mean([df['Weekly_Sales'][idx] for idx in both if major_holidays[idx]=='super_bowl' and df['Weekly_Sales'][idx]>0])\n",
    "    labor_day_mean = np.mean([df['Weekly_Sales'][idx] for idx in both if major_holidays[idx]=='labor_day' and df['Weekly_Sales'][idx]>0])\n",
    "    thanksgiving_mean = np.mean([df['Weekly_Sales'][idx] for idx in both if major_holidays[idx]=='thanksgiving' and df['Weekly_Sales'][idx]>0])\n",
    "    xmas_mean =  np.mean([df['Weekly_Sales'][idx] for idx in both if major_holidays[idx]=='xmas' and df['Weekly_Sales'][idx]>0])\n",
    "    \n",
    "    major_holiday_means[(dept,store,'super_bowl')] = super_bowl_mean\n",
    "    major_holiday_means[(dept,store,'labor_day')] = labor_day_mean\n",
    "    major_holiday_means[(dept,store,'thanksgiving')] = thanksgiving_mean\n",
    "    major_holiday_means[(dept,store,'xmas')] = xmas_mean\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean data from given week in a dept at given store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_one_weekly_sales(dept,store,date):\n",
    "    try:\n",
    "        df = dfs[(dept,store)]    \n",
    "        indices = sorted(df.index)\n",
    "\n",
    "        normal_weeks = [idx for idx in indices if df['IsHoliday'][idx]==False and df['Weekly_Sales'][idx]>0] \n",
    "\n",
    "        # date of value used for imputation for given date\n",
    "        pos = min(range(len(normal_weeks)), key=lambda i: abs(normal_weeks[i]-date))\n",
    "        imputation_date = normal_weeks[pos]\n",
    "\n",
    "        imputation_value = df['Weekly_Sales'][imputation_date]\n",
    "        # pass imputation by reference\n",
    "        df['Weekly_Sales'][date] = imputation_value\n",
    "                \n",
    "        if date not in indices:\n",
    "            print('invalid date')\n",
    "            return\n",
    "        \n",
    "        if date not in major_holidays.keys(): #implement holiday cases later\n",
    "        #if df[date]['IsHoliday']==False:\n",
    "            \n",
    "            normal_weeks = [idx for idx in indices if df['IsHoliday'][idx]==False and df['Weekly_Sales'][idx]>0] \n",
    "            \n",
    "             # date of value used for imputation for given date\n",
    "            imputation_date = min(enumerate(normal_weeks), key=lambda x: abs((normal_weeks[1]-date).days))[1]\n",
    "            imputation_value = df['Weekly_Sales'][imputation_date]\n",
    "            # pass imputation by reference\n",
    "            df['Weekly_Sales'][date] = imputation_value\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            holiday = major_holidays[date]\n",
    "            \n",
    "            #print((dept,store,holiday))\n",
    "            \n",
    "            imputation_value = major_holiday_means[(dept,store,holiday)]\n",
    "            #print('here')\n",
    "            \n",
    "            if pd.isnull(imputation_value):\n",
    "                holiday_weeks = [idx for idx in indices if df['IsHoliday'][idx]==True and df['Weekly_Sales'][idx]>0]\n",
    "                imputation_value = np.mean(df['Weekly_Sales'][holiday_weeks])\n",
    "            df['Weekly_Sales'][date] = imputation_value\n",
    "            return   \n",
    "            \n",
    "    except:\n",
    "        print('invalid (dept,store)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean data from multiple weeks in a dept at a given store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_multiple_weekly_sales(dept,store,dates):\n",
    "    for d in dates:\n",
    "        impute_one_weekly_sales(dept,store,d) \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean all data from a dept at a given store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_all_weekly_sales(dept,store):\n",
    "    \n",
    "    print('impute: store =', store)\n",
    "    \n",
    "    df = dfs[(dept,store)]    \n",
    "    indices = sorted(df.index)\n",
    "        \n",
    "    dates = [idx for idx in indices if df['Weekly_Sales'][idx]<0.01]\n",
    "    impute_multiple_weekly_sales(dept,store,dates) \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = dfs.keys()\n",
    "stores_has_dept = {}\n",
    "for dept in all_depts:\n",
    "    stores_has_dept[dept] = []\n",
    "for dept,store in keys:\n",
    "    stores_has_dept[dept].append(store)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean data from given dept and save it in a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dept_sales(dept):\n",
    "    \n",
    "    store_list = stores_has_dept[dept]\n",
    "    for store in store_list:\n",
    "        impute_all_weekly_sales(dept, store)\n",
    "     \n",
    "    cleaned_sales_list= []\n",
    "    for store in store_list:\n",
    "        print('dept = ',dept, 'add to list: store = ',store)\n",
    "        \n",
    "        df = dfs[(dept,store)]\n",
    "        df = df.reset_index()\n",
    "        n_rows = df.shape[0]\n",
    "        df['Store']= [store]*n_rows\n",
    "        df['Dept']=[dept]*n_rows\n",
    "        #rearrange order of columns\n",
    "        df = df[list(sales.columns)]\n",
    "        cleaned_sales_list.append(df)\n",
    "    \n",
    "    if (len(cleaned_sales_list)>0):\n",
    "        result = pd.concat(cleaned_sales_list)\n",
    "        result.to_pickle('data/clean_sales_dept_'+str(dept)+'.pkl')\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean all sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dept in all_depts:\n",
    "    clean_dept_sales(dept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
