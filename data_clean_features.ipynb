{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_clean_features\n",
    "clean meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and normalize dates: since we are dealing with weekly sales, on which day an entry got recorded is not important. Rather, normalize them by converting them to the date of Monday of the same week.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('data/features.csv')\n",
    "\n",
    "\n",
    "# since we are dealing with weekly data, on which day an entry got recorded is not important\n",
    "# rather, we will normalize them by converting them to the date of Monday of the same week.\n",
    "# later we will aggregate weekly sales by summing all the entry on the same normalized date.\n",
    "def year_week(date):\n",
    "    temp = date.isocalendar()\n",
    "    date_string = str(temp[0])+' '+str(temp[1])+' 1'\n",
    "    return datetime.datetime.strptime(date_string, '%G %V %u')\n",
    "\n",
    "# normalize dates\n",
    "features['Date'] = pd.to_datetime(features['Date'])\n",
    "features['Date'] = features['Date'].apply(year_week)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are multiple rows on some dates, some with confilicting information. The following code consolidates rows into one for each date by taking the mean.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_features=features.groupby(['Store','Date']).apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_features=clean_features.reset_index(level='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, impute missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_features = clean_features.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.89</td>\n",
       "      <td>2.6030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.671989</td>\n",
       "      <td>7.8380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.59</td>\n",
       "      <td>2.6940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.021992</td>\n",
       "      <td>7.7975</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.5140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.1060</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.5610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.1060</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.24</td>\n",
       "      <td>2.6425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.569220</td>\n",
       "      <td>7.8125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Store  Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  \\\n",
       "0 2010-01-04    1.0        71.89      2.6030        NaN        NaN        NaN   \n",
       "1 2010-02-01    1.0        71.59      2.6940        NaN        NaN        NaN   \n",
       "2 2010-02-15    1.0        39.93      2.5140        NaN        NaN        NaN   \n",
       "3 2010-02-22    1.0        46.63      2.5610        NaN        NaN        NaN   \n",
       "4 2010-03-08    1.0        65.24      2.6425        NaN        NaN        NaN   \n",
       "\n",
       "   MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
       "0        NaN        NaN  211.671989        7.8380        0.0  \n",
       "1        NaN        NaN  211.021992        7.7975        0.0  \n",
       "2        NaN        NaN  211.289143        8.1060        0.0  \n",
       "3        NaN        NaN  211.319643        8.1060        0.0  \n",
       "4        NaN        NaN  211.569220        7.8125        0.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7200 entries, 0 to 7199\n",
      "Data columns (total 12 columns):\n",
      "Date            7200 non-null datetime64[ns]\n",
      "Store           7200 non-null float64\n",
      "Temperature     7200 non-null float64\n",
      "Fuel_Price      7200 non-null float64\n",
      "MarkDown1       3672 non-null float64\n",
      "MarkDown2       2760 non-null float64\n",
      "MarkDown3       3285 non-null float64\n",
      "MarkDown4       3164 non-null float64\n",
      "MarkDown5       3690 non-null float64\n",
      "CPI             6660 non-null float64\n",
      "Unemployment    6660 non-null float64\n",
      "IsHoliday       7200 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(11)\n",
      "memory usage: 675.1 KB\n"
     ]
    }
   ],
   "source": [
    "# columns contain missing values include CPI, Unemployment and markdowns\n",
    "clean_features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace missing markdown values by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_features['MarkDown1']=clean_features['MarkDown1'].fillna(0)\n",
    "clean_features['MarkDown2']=clean_features['MarkDown2'].fillna(0)\n",
    "clean_features['MarkDown3']=clean_features['MarkDown3'].fillna(0)\n",
    "clean_features['MarkDown4']=clean_features['MarkDown4'].fillna(0)\n",
    "clean_features['MarkDown5']=clean_features['MarkDown5'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate the patterns of missing values for Unemployment and CPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "       14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
       "       27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.,\n",
       "       40., 41., 42., 43., 44., 45.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are missing values for unemployment in every store\n",
    "mask = pd.isnull(clean_features['Unemployment'])\n",
    "clean_features[cpi_mask]['Store'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CPI and Unemployment always miss together in the same rows\n",
    "\n",
    "cpi_na_index = pd.isnull(clean_features[['CPI']]).any(1).nonzero()[0]\n",
    "unemployment_na_index = pd.isnull(clean_features[['Unemployment']]).any(1).nonzero()[0]\n",
    "cpi_na_index == unemployment_na_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing CPI and Unemployment values from the same store on the closest date when these values are not missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "storeIDs = sorted(clean_features['Store'].unique())\n",
    "dfs = []\n",
    "\n",
    "for storeID in storeIDs:\n",
    "    store_mask = (clean_features['Store'] == storeID)\n",
    "    df = clean_features[store_mask]\n",
    "    # CPI missing values are in the same rows too as CPI and Unemployment \n",
    "    # always missing together \n",
    "    na_index = pd.isnull(df[['Unemployment']]).any(1).nonzero()[0]    \n",
    "    all_index = [i for i in range(df.shape[0])]\n",
    "    non_na_index = [i for i in all_index if i not in na_index]\n",
    "    \n",
    "    for k in na_index:\n",
    "        # find the closest row that has none missing cpi and unemployment; \n",
    "        # use these values for imputation\n",
    "        impute_index = min(non_na_index, key=lambda x:abs(x-k))\n",
    "\n",
    "        df['Unemployment'].iloc[k] = df['Unemployment'].iloc[impute_index]\n",
    "        df['CPI'].iloc[k] = df['CPI'].iloc[impute_index]\n",
    "        \n",
    "    dfs.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7200 entries, 0 to 7199\n",
      "Data columns (total 12 columns):\n",
      "Date            7200 non-null datetime64[ns]\n",
      "Store           7200 non-null float64\n",
      "Temperature     7200 non-null float64\n",
      "Fuel_Price      7200 non-null float64\n",
      "MarkDown1       7200 non-null float64\n",
      "MarkDown2       7200 non-null float64\n",
      "MarkDown3       7200 non-null float64\n",
      "MarkDown4       7200 non-null float64\n",
      "MarkDown5       7200 non-null float64\n",
      "CPI             7200 non-null float64\n",
      "Unemployment    7200 non-null float64\n",
      "IsHoliday       7200 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(11)\n",
      "memory usage: 731.2 KB\n"
     ]
    }
   ],
   "source": [
    "clean_features = pd.concat(dfs)\n",
    "clean_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.89</td>\n",
       "      <td>2.6030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.671989</td>\n",
       "      <td>7.8380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.59</td>\n",
       "      <td>2.6940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.021992</td>\n",
       "      <td>7.7975</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.5140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.1060</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.5610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.1060</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.24</td>\n",
       "      <td>2.6425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.569220</td>\n",
       "      <td>7.8125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Store  Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  \\\n",
       "0 2010-01-04    1.0        71.89      2.6030        0.0        0.0        0.0   \n",
       "1 2010-02-01    1.0        71.59      2.6940        0.0        0.0        0.0   \n",
       "2 2010-02-15    1.0        39.93      2.5140        0.0        0.0        0.0   \n",
       "3 2010-02-22    1.0        46.63      2.5610        0.0        0.0        0.0   \n",
       "4 2010-03-08    1.0        65.24      2.6425        0.0        0.0        0.0   \n",
       "\n",
       "   MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
       "0        0.0        0.0  211.671989        7.8380        0.0  \n",
       "1        0.0        0.0  211.021992        7.7975        0.0  \n",
       "2        0.0        0.0  211.289143        8.1060        0.0  \n",
       "3        0.0        0.0  211.319643        8.1060        0.0  \n",
       "4        0.0        0.0  211.569220        7.8125        0.0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save cleaned features to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_features.to_pickle('data/clean_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_features = pd.read_pickle('clean_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
